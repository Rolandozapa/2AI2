<analysis>
This trajectory chronicles the transformation of a Dual AI Trading Bot from an MVP into an Ultra Professional Edition. The AI engineer iteratively addressed user requests, starting with the implementation and verification of a dynamic leverage and 5-level take-profit system, after initial tests revealed critical missing logic despite prior claims of completion. Subsequent work focused on robust risk management, introducing a leverage-proportional trailing stop-loss system with email notifications. A significant portion of the work involved correcting discrepancies and optimizing LLM credit consumption, first by moving to a 4-hour scout cycle and then by implementing a multi-stage, bidirectional Risk-Reward filtering mechanism, ensuring only high-quality opportunities reach the costly AI models. Critical bugs related to duplicate processing by IA1 and IA2 were identified and resolved through comprehensive deduplication logic across opportunities, IA1 analyses, and IA2 decisions, aligning with the 4-hour cycle. The final major correction in progress involves moving these deduplication checks *before* LLM calls to prevent wasted credits. Localization to Paris time was also integrated across the entire application.
</analysis>

<product_requirements>
The goal is to build a sophisticated Dual AI Trading Bot with React frontend, FastAPI backend, and MongoDB. The system features a scout for market opportunities, IA1 (GPT-4o) for technical analysis, and IA2 (Claude-3-7-Sonnet) for strategic decisions. It integrates real market data from 8+ APIs with multi-threaded fallback, pre-filters opportunities using a  for chart patterns, and optimizes API calls. Core features include multi-level take-profit strategies, automatic position inversion, dynamic leverage based on market sentiment and IA2 confidence, and full BingX Futures account control for trade execution and real-time balance display. The user requested granular control over AI credit consumption via Start/Stop buttons. Enhancements during this trajectory specifically included: implementing a robust historical data fallback system; fixing IA1-IA2 data flow and LLM budget issues; resolving frontend connectivity; establishing full BingX account control (IP whitelisting, API keys); integrating a 5-level dynamic take-profit strategy and dynamic leverage; implementing a leverage-proportional trailing stop-loss with email notifications; setting application timestamps to Paris time; changing the scout cycle frequency to 4 hours; implementing a Risk-Reward filter (min 2:1 for IA1, then pre-filter in Scout) to save LLM credits; fixing R:R calculation consistency between IA1 and IA2; implementing comprehensive deduplication across opportunities, IA1 analyses, and IA2 decisions to prevent re-analysis within a 4-hour cycle.
</product_requirements>

<key_technical_concepts>
-   **FastAPI**: Python web framework for backend.
-   **React**: JavaScript library for frontend UI.
-   **MongoDB**: NoSQL database for data storage.
-   **OpenAI GPT-4o, Claude-3-7-Sonnet**: AI models (IA1/IA2).
-   **Multi-threading/AsyncIO**: Parallel data processing.
-   **BingX API ( SDK)**: Live crypto trading, balance, order execution.
-   **Technical Analysis**: RSI, MACD, Bollinger Bands, Fibonacci, chart patterns, Risk-Reward.
-   **WebSockets**: Real-time frontend updates.
-   **Dynamic Leverage/SL/TP/Trailing Stop-Loss**: Adaptive trading parameters.
-   **pytz**: Python library for timezone management.
</key_technical_concepts>

<code_architecture>

-   : Main FastAPI entry point and orchestrator.
    -   **Importance**: Coordinates AI analysis, market data, trading, WebSockets, and manages the entire trading cycle. It houses the  class.
    -   **Changes Made**:
        -   Fixed parsing/application of dynamic leverage and 5-level take-profit from Claude's response within  and .
        -   Implemented leverage-proportional trailing stop-loss system: added data models, integrated logic into decision-making, created background monitor, and exposed API endpoints ().
        -   Integrated Paris timezone ( import, , ), updating timestamps in all Pydantic data models (, , , etc.), API endpoints (, , , ), and WebSocket updates.
        -   Corrected the  endpoint to properly call .
        -   Modified the main scout cycle interval to 4 hours ().
        -   Implemented IA1 Risk-Reward calculation () including , ,  fields in  model, and a pre-IA2 filter for R:R ≥ 2:1 ().
        -   Implemented a bidirectional Risk-Reward pre-filter in the Scout, with adaptive factors for each token (momentum, volatility) to provide a nuanced R:R.
        -   Implemented deduplication logic for , , and  based on symbol and a 4-hour window, to ensure each crypto is processed only once per cycle.
        -   **Latest change**: Moved IA1 deduplication check to *before* the LLM call to save credits, still in progress for IA2.
-   : Environment variables.
    -   **Importance**: Stores API keys and database connection string.
    -   **Changes Made**: Updated BingX API key and secret key for live trading.
-   :
    -   **Importance**: Pre-filters opportunities by detecting chart patterns.
    -   **Changes Made**: No direct changes described, but confirmed to contain  for 20+ chart patterns (Head & Shoulders, Triangles, Flags, etc.), used as a filter before IA1.
</code_architecture>

<pending_tasks>
-   Move IA2's deduplication logic to *before* its LLM call to save credits, as was done for IA1.
</pending_tasks>

<current_work>
The AI engineer is currently in the process of optimizing LLM credit consumption by refactoring the deduplication logic. Previously, deduplication for IA1 analyses and IA2 decisions was performed *after* the LLM calls, meaning credits were wasted on processing duplicate opportunities. This critical flaw was identified by the user.

The work completed so far includes:
1.  **IA1 Deduplication Relocation**: The deduplication check for IA1 analyses has been successfully moved to occur *before* the actual IA1 (GPT-4o) LLM call. This ensures that if a crypto has already been analyzed within the 4-hour deduplication window, IA1 is skipped entirely, saving LLM credits.
2.  **IA2 Deduplication Relocation (In Progress)**: The AI engineer has just started to implement the same pre-LLM call deduplication for IA2 decisions. The process involves identifying the exact location in the code () where IA2 decisions are processed and stored, and then implementing a check to determine if a decision for the same crypto has already been made within the 4-hour window *before* invoking the IA2 (Claude-3-7-Sonnet) LLM. The previous attempt faced a structure mismatch, requiring further investigation into IA2's processing flow.

The immediate goal is to ensure IA2's deduplication is correctly placed to prevent any wasted LLM credits, aligning with the IA1 = Source unique de vérité architectural principle and maximizing credit efficiency across the entire trading pipeline.
</current_work>

<optional_next_step>
Identify the correct structure and location to move IA2's deduplication logic to *before* its LLM call.
</optional_next_step>
